---
title: "crossvalidation vs MAP"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rstan)
library(glmnet)
```

# Crossvalidation vs MAP
Here we genereate correlated data

```{r data generation}
N_samples <- 100
height <- rnorm(N_samples, 10, 2)
leg_prop <- runif(N_samples, 0.4, 0.5)
leg_left <- leg_prop * height + rnorm(N_samples, 0, 0.02)
leg_right <- leg_prop * height + rnorm(N_samples, 0, 0.02)
d <- data.frame(height, leg_left, leg_right)
```


```{stan output.var="height_inference_5_8"}
data {
  int<lower=0> N_samples;
  vector[N_samples] height;
  vector[N_samples] leg_left;
  vector[N_samples] leg_right;
}
parameters {
  real a;
  real bl;
  real br;
  real<lower=0> sigma;
}
model {
	a ~ normal(10, 100);
	bl ~ normal(2, 1);
	br ~ normal(2, 1);
  sigma ~ uniform(0,10);
  height ~ normal(a + bl *leg_left + br * leg_right, sigma);
}
```
## MAP estimate for estimating mu at max sample mean

```{r}
fit <- optimizing(height_inference_5_8, data = list(N_samples=N_samples, height=height, leg_left=leg_left, leg_right=leg_right), as_vector=FALSE, hessian=TRUE)
vcov <- try( solve(fit$hessian) )  
#?? vcov 

```

Use penalised ML with glmnet.
the regularisation defaults much stronger.  How is this identified?
(but then crossvalidate) .. and might not identify minimum in section

Cannot set this up as a random effects model?

```{r}

X <- as.matrix(d[,c("leg_left", "leg_right")])
y <- as.matrix(d$height)
md <- cv.glmnet(X, y, alpha=0, standardize=FALSE, lambda = seq(0.0001,0.01,length.out=1000))
cat(md$lambda.min, md$lambda.1se,fit$par$sigma)
sigma_b <- fit$par$sigma / sqrt(min(md$lambda *N_samples))
sds <- sqrt(diag(vcov(m5.8)))
lambda <- (coef(m5.8)["sigma"]/sds["bl"])^2/N
md$glmnet.fit$beta
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
